# Install the required libraries
#!pip install prophet
#!pip install jupyter_bokeh --upgrade
#!pip install hvplot --upgrade
#!pip install prophet



#import supporting liberaries - Panda, Matplotlib, Prophet, Numpy, hvplot
import pandas as pd
import matplotlib.pyplot as plt
import prophet as Prophet
import numpy as np
import datetime as dt
import hvplot.pandas
import panel as pn # for panels to use with hvplot.points



#upload ufoSighting.csv - available at https://docs.google.com/spreadsheets/d/1iNNPzkDTDiaTnbYqBY4ELH_0rPts2uXgl_JSdKCEgUE/edit?usp=drive_link
path = 'resources/ufoSightings.csv'


#importing csv file in a dataframe
ufo_sightings_df = pd.read_csv(path,
                 #index_col="datetime",
                 parse_dates=['datetime'],
                 infer_datetime_format=True
                )

# Preview the dataset
ufo_sightings_df.head()


#cast datetime column as datetime datatype - #convert datetime column to datetime format
ufo_sightings_df['datetime'] = pd.to_datetime(ufo_sightings_df['datetime'], errors='coerce')
#ufo_sightings_df['datetime_1'] = ufo_sightings_df['datetime'].dt.strftime('%m/%d/%Y %H:%M')
ufo_sightings_df.dtypes


#create a slice for country=us and drop any blank values and display first 5 and last 5 columns
us_ufo_df = ufo_sightings_df[ufo_sightings_df['country'] == 'us']
us_ufo_df = us_ufo_df.dropna(how='any')
display(us_ufo_df.head())
display(us_ufo_df.tail())


#drop unwanted columns like duration hour/min, comments, date posted
cleaned_us_ufo_df = us_ufo_df.drop(columns=['duration (hours/min)', 'comments', 'date posted'])
#cleaned_us_ufo_df.head()


#sorting data by datetime column
cleaned_us_ufo_df.sort_values(by=['datetime'], inplace=True)
cleaned_us_ufo_df.shape


#Checking range data available in dataset
display(cleaned_us_ufo_df['datetime'].min())
cleaned_us_ufo_df['datetime'].max()


#casting duration in seconds to float to perform agreegation
# Convert 'duration (seconds)' to numeric before calculating mean
cleaned_us_ufo_df['duration (seconds)'] = pd.to_numeric(cleaned_us_ufo_df['duration (seconds)'], errors='coerce')

#cleaned_us_ufo_df['duration (seconds)'] = cleaned_us_ufo_df['duration (seconds)'].astype(float)
#check to ensure conversion of column type
cleaned_us_ufo_df.dtypes


#add a column for year by extracting from datetime column to use for grouping and display last (10) records
cleaned_us_ufo_df['year'] = cleaned_us_ufo_df['datetime'].dt.year
cleaned_us_ufo_df.tail(10)


cleaned_us_ufo_df_copy = cleaned_us_ufo_df.copy()
cleaned_us_ufo_df_copy.dropna()
cleaned_us_ufo_df_copy.tail()
# drop NaT values from datetime
cleaned_us_ufo_df_copy = cleaned_us_ufo_df_copy[cleaned_us_ufo_df_copy['datetime'].notna()]
cleaned_us_ufo_df_copy.tail()


#create a pivot table for average sighting by year and visualize bar graph
us_ufo_df_year_avg = pd.pivot_table(cleaned_us_ufo_df,
                                    index='year',
                                    values='duration (seconds)',
                                    aggfunc='mean').round(1)
display(us_ufo_df_year_avg.tail(20))
display(us_ufo_df_year_avg.plot(kind='bar', title='Mean of seconds of UFO Sightings by Year'))


us_ufo_df_year = pd.pivot_table(cleaned_us_ufo_df,
                             index='year',
                             values='duration (seconds)',
                             aggfunc='count').round(1)
display(us_ufo_df_year.tail(30))
us_ufo_df_year.plot(kind='bar', title='Count of UFO Sightings by Year')


#create a dateframe from us_ufo_df_year where duration (seconds) is greater than 300
us_ufo_df_year_over_300 = us_ufo_df_year[us_ufo_df_year['duration (seconds)'] > 300]

#take 1st value of index and store it to variable named selected
selected = us_ufo_df_year_over_300.index[0]


#group a dataframe by state and aggregate by count and sum

cleaned_us_ufo_df.groupby('state').agg({'duration (seconds)': ['count', 'sum', 'mean']}).head()


#based on analysis, extracting data for year which has data over 300
cleaned_us_ufo_df_new = cleaned_us_ufo_df[cleaned_us_ufo_df['year'] >= selected]
cleaned_us_ufo_df_new.head()


#calculate count and avg duration anf group by state after 1990
us_ufo_state_count = pd.pivot_table(cleaned_us_ufo_df_new,
                             index='state',
                             values='duration (seconds)',
                             aggfunc='count').round(1)
us_ufo_state_count = us_ufo_state_count.sort_values(by=['duration (seconds)'], ascending=False)
#Selecting top 10 states by count
top_10_states_count = us_ufo_state_count[:10]
top_10_states_count


#agregate by mean and create a pivot table
us_ufo_state_average = pd.pivot_table(cleaned_us_ufo_df_new,
                             index='state',
                             values='duration (seconds)',
                             aggfunc='mean').round(1)

us_ufo_state_average =us_ufo_state_average.sort_values(by=['duration (seconds)'], ascending=False)
top_10_states_average = us_ufo_state_average[:10]
top_10_states_average


#agregate by mean and create a pivot table
us_ufo_state_total_seconds = pd.pivot_table(cleaned_us_ufo_df_new,
                             index='state',
                             values='duration (seconds)',
                             aggfunc='sum').round(1)

us_ufo_state_total_seconds =us_ufo_state_total_seconds.sort_values(by=['duration (seconds)'], ascending=False)
us_ufo_state_total_seconds = us_ufo_state_total_seconds[:10]
us_ufo_state_total_seconds


us_ufo_state_df = pd.merge(us_ufo_state_count, us_ufo_state_average, on='state')
us_ufo_state_df.columns = ['count', 'average_duration']
display(us_ufo_state_df.head())
display(us_ufo_state_df.tail())


us_ufo_state_df.describe()


count_percentile80 = us_ufo_state_df['count'].quantile(0.8)
count_percentile90 = us_ufo_state_df['count'].quantile(0.9)
avg_percentile80 = us_ufo_state_df['average_duration'].quantile(0.8)
avg_percentile90 = us_ufo_state_df['average_duration'].quantile(0.9)

print(f"90% quantile of average duration is {round(avg_percentile90,2)}")
print(f"80% quantile of average duration is {round(avg_percentile80,2)}")
print(f"90% quantile of count is {count_percentile90}")
print(f"80% quantile of count is {count_percentile80}")



# create a dataframe from us_ufo_state_df that has count and avg duration greater than or equalt to 90 percentile
#us_ufo_state_top_df = us_ufo_state_df[us_ufo_state_df['count'] > count_percentile80]
us_ufo_state_top_df = us_ufo_state_df[(us_ufo_state_df['count'] >= count_percentile90) | (us_ufo_state_df['average_duration'] >= avg_percentile90)]
us_ufo_state_top_df = us_ufo_state_top_df.sort_values(by=["state"])


#adding columns for calculating minutes and hour
us_ufo_state_top_df["average_duration_min"] = us_ufo_state_top_df['average_duration'] / 60
us_ufo_state_top_df["average_duration_hour"] = us_ufo_state_top_df['average_duration_min'] / 60
us_ufo_state_top_df.reset_index(inplace=True)
us_ufo_state_top_df


# Create a subplots to show data by counts and seconds side by side
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))  # 1 row, 2 columns

# Plot the number of sightings on the first subplot
ax1.bar(us_ufo_state_top_df['state'], us_ufo_state_top_df['count'], color='blue')
ax1.set_xlabel('State')
ax1.set_ylabel('Number of Sightings')
ax1.set_title('Number of UFO Sightings')
ax1.tick_params(axis='x', rotation=90)

# Plot the average duration on the second subplot
ax2.bar(us_ufo_state_top_df['state'], us_ufo_state_top_df['average_duration'], color='red')
ax2.set_xlabel('State')
ax2.set_ylabel('Average Duration (seconds)')
ax2.set_title('Average Duration of UFO Sightings')
ax2.tick_params(axis='x', rotation=90)

# Adjust layout to prevent labels from overlapping
plt.tight_layout()

# Display the plot
plt.show()
plt.savefig('ufo_sightings_subplots.png')



#creatihg bubble chart to show states in top 90% counts
plt.figure(figsize=(12, 8))
fig = plt.scatter(us_ufo_state_top_df["state"], us_ufo_state_top_df["average_duration_min"], s=us_ufo_state_top_df["count"], alpha=0.5)
plt.ylim(-10, 400)
plt.title("Number of Sightings")
plt.xlabel("State")
plt.ylabel("Average duration in minutes")
legend = plt.legend(*fig.legend_elements(), title="Count of sightings")
plt.gca().add_artist(legend)
plt.show(fig)
plt.savefig('ufo_sightings_by_state.png')


#import matplotlib.pyplot as plt


# Calculate the correlation coefficient
correlation = us_ufo_state_top_df['count'].corr(us_ufo_state_top_df['average_duration_min'])
print("Correlation coefficient:", correlation)



# Create a scatter plot
plt.figure(figsize=(8, 6))
plt.scatter(us_ufo_state_top_df['count'], us_ufo_state_top_df['average_duration_min'], alpha=0.7)
plt.xlabel('Number of Sightings')
plt.ylabel('Average Duration (min)')
plt.title('Correlation between Number of Sightings and Average Duration')

# Calculate and add the correlation coefficient to the plot
correlation = us_ufo_state_top_df['count'].corr(us_ufo_state_top_df['average_duration'])
plt.text(0.5, 0.9, f"Correlation: {correlation:.2f}", transform=plt.gca().transAxes)

plt.grid(True)
plt.show()
plt.savefig('correlation_sighting_duration.png')



florida_df = cleaned_us_ufo_df_new.loc[cleaned_us_ufo_df_new['state'] == 'fl']
florida_seconds_sum_df = pd.pivot_table(florida_df,
                            index='datetime',
                            values='duration (seconds)',
                            aggfunc='sum').round(1)
florida_seconds_sum_df = florida_seconds_sum_df.rename(columns={'duration (seconds)': 'total_seconds'})
florida_seconds_sum_df.reset_index(inplace=True)
florida_seconds_sum_df.head()


washington_df = cleaned_us_ufo_df_new.loc[cleaned_us_ufo_df_new['state'] == 'wa']
washington_seconds_sum_df = pd.pivot_table(washington_df,
                            index='datetime',
                            values='duration (seconds)',
                            aggfunc='sum').round(1)
washington_seconds_sum_df = washington_seconds_sum_df.rename(columns={'duration (seconds)': 'total_seconds'})
washington_seconds_sum_df.reset_index(inplace=True)
washington_seconds_sum_df.head()


california_df = cleaned_us_ufo_df_new.loc[cleaned_us_ufo_df_new['state'] == 'ca']
california_seconds_sum_df = pd.pivot_table(california_df,
                            index='datetime',
                            values='duration (seconds)',
                            aggfunc='sum').round(1)
california_seconds_sum_df = california_seconds_sum_df.rename(columns={'duration (seconds)': 'total_seconds'})
california_seconds_sum_df.reset_index(inplace=True)
california_seconds_sum_df.head()


florida_seconds_sum_df.columns = ["ds", "y"]
washington_seconds_sum_df.columns = ["ds", "y"]
california_seconds_sum_df.columns = ["ds", "y"]



!pip install prophet

# Step 2: Import the Prophet class
from prophet import Prophet


#creating variables for forecasting period and frequency
forecasting_period = 10
forecasting_frequency = 'Y' #for year


model = Prophet()
model.fit(washington_seconds_sum_df)
future_trends_wa = model.make_future_dataframe(periods=forecasting_period, freq=forecasting_frequency)
forecast_trends_wa = model.predict(future_trends_wa)
model.plot(forecast_trends_wa);
figures = model.plot_components(forecast_trends_wa)
plt.savefig('forecast_washington_components.png')


model = Prophet()
model.fit(florida_seconds_sum_df)
florida_future = model.make_future_dataframe(periods=forecasting_period, freq=forecasting_frequency)
fl_forecast = model.predict(florida_future)
print('Displaying forecasting model graph and components graph for Florida to show possibilities of UFO showings over next 10 years')
model.plot(fl_forecast);
figures = model.plot_components(fl_forecast)
plt.savefig('forecast_florida_components.png')


model = Prophet()
model.fit(california_seconds_sum_df)
california_future = model.make_future_dataframe(periods=forecasting_period, freq=forecasting_frequency)
ca_forecast = model.predict(california_future)
model.plot(ca_forecast);
figures = model.plot_components(ca_forecast)
plt.savefig('forecast_california_components.png')


# add a new empty column to ufo_shape_data labeled 'form'
cleaned_us_ufo_df['form'] = ''
cleaned_us_ufo_df.head()
# if value in ufo_shape_data_df['shape'] column equals cigar, circle, round, sphere, oval, egg, cylinder or disk, then value in ufo_shape_data_df['form'] column equals circular
cleaned_us_ufo_df.loc[cleaned_us_ufo_df['shape'].isin(['cigar', 'circle', 'round', 'sphere', 'oval', 'egg', 'cylinder', 'disk']), 'form'] = 'circular'
# if value in ufo_shape_data_df['shape'] column equals fireball, flare, flash or light, then value in ufo_shape_data_df['form'] column equals light
cleaned_us_ufo_df.loc[cleaned_us_ufo_df['shape'].isin(['fireball', 'flare', 'flash', 'light']), 'form'] = 'light'
# if value in ufo_shape_data_df['shape'] column equals chevron, delta, triangle, pyramid or cone, then value in ufo_shape_data_df['form'] column equals triangle
cleaned_us_ufo_df.loc[cleaned_us_ufo_df['shape'].isin(['chevron', 'delta', 'triangle', 'pyramid', 'cone']), 'form'] = 'triangle'
# if value in ufo_shape_data_df['shape'] column equals formation, changed or changing, then value in ufo_shape_data_df['form'] column equals formation_changing
cleaned_us_ufo_df.loc[cleaned_us_ufo_df['shape'].isin(['formation', 'changed', 'changing']), 'form'] = 'formation_changing'
# if value in ufo_shape_data_df['shape'] column equals diamond, hexagon, crescent, cross, rectangle or teardrop, then value in ufo_shape_data_df['form'] column equals geometric
cleaned_us_ufo_df.loc[cleaned_us_ufo_df['shape'].isin(['diamond', 'hexagon', 'crescent', 'cross', 'rectangle', 'teardrop']), 'form'] = 'geometric'
# if value in ufo_shape_data_df['shape'] column equals other or unknown, then value in ufo_shape_data_df['form'] column equals other_unknown
cleaned_us_ufo_df.loc[cleaned_us_ufo_df['shape'].isin(['other', 'unknown']), 'form'] = 'other_unknown'
cleaned_us_ufo_df.head()


#agreegating count of form by grouping on form
cleaned_us_ufo_df.groupby('form').agg({'form': ['count']}).sort_values(by=[('form', 'count')], ascending=False)


#getting list of states from dataframe with 90 perenctile records
geocoding_top_states = us_ufo_state_top_df['state'].tolist()
geocoding_top_states


#convert states to uppercase to be able to match with publicly sourced data
states = [s.upper() for s in geocoding_top_states]
states


abbreviation_to_name = {
    # https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States#States.
    "AK": "Alaska",
    "AL": "Alabama",
    "AR": "Arkansas",
    "AZ": "Arizona",
    "CA": "California",
    "CO": "Colorado",
    "CT": "Connecticut",
    "DE": "Delaware",
    "FL": "Florida",
    "GA": "Georgia",
    "HI": "Hawaii",
    "IA": "Iowa",
    "ID": "Idaho",
    "IL": "Illinois",
    "IN": "Indiana",
    "KS": "Kansas",
    "KY": "Kentucky",
    "LA": "Louisiana",
    "MA": "Massachusetts",
    "MD": "Maryland",
    "ME": "Maine",
    "MI": "Michigan",
    "MN": "Minnesota",
    "MO": "Missouri",
    "MS": "Mississippi",
    "MT": "Montana",
    "NC": "North Carolina",
    "ND": "North Dakota",
    "NE": "Nebraska",
    "NH": "New Hampshire",
    "NJ": "New Jersey",
    "NM": "New Mexico",
    "NV": "Nevada",
    "NY": "New York",
    "OH": "Ohio",
    "OK": "Oklahoma",
    "OR": "Oregon",
    "PA": "Pennsylvania",
    "RI": "Rhode Island",
    "SC": "South Carolina",
    "SD": "South Dakota",
    "TN": "Tennessee",
    "TX": "Texas",
    "UT": "Utah",
    "VA": "Virginia",
    "VT": "Vermont",
    "WA": "Washington",
    "WI": "Wisconsin",
    "WV": "West Virginia",
    "WY": "Wyoming",
    # https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States#Federal_district.
    "DC": "District of Columbia",
    # https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States#Inhabited_territories.
    "AS": "American Samoa",
    "GU": "Guam GU",
    "MP": "Northern Mariana Islands",
    "PR": "Puerto Rico PR",
    "VI": "U.S. Virgin Islands",
}


#credit: https://gist.github.com/JeffPaine/3083347


#creating list of state abbreviation and name from abbreviation_to_name
states_dict = {s.lower(): abbreviation_to_name[s] for s in states}
states_dict


#getting list of states from newly created dictionary
states_lower_abb = [s for s in states_dict]
states_lower_abb


#creating copy of the dataframe to maintain original data
geo_df = cleaned_us_ufo_df.loc[cleaned_us_ufo_df['state'].isin(geocoding_top_states)]
geo_df


#mapping state name by looking up state abbreviation column in dictionary
geo_df['state_name'] = geo_df['state'].map(lambda x: states_dict[x])
geo_df


geo_df["average_duration_min"] = geo_df['duration (seconds)'] / 60
geo_df["average_duration_hour"] = geo_df['average_duration_min'] / 60
geo_df.sort_values(by=['state'], inplace=True)
display(geo_df.head())


#Error while plotting: Geographic projection support requires: cartopy, geoviews.
#!pip install cartopy
#!pip install geoviews


!import panel as pn


# Load the cleaned data
#cleaned_ufo_df = pd.read_csv('cleaned_ufo_data.csv', index_col=False)

# Ensure there are no leading/trailing spaces in column names
geo_df.columns = geo_df.columns.str.strip()

# Drop the unnamed column if it exists
geo_df = geo_df.loc[:, ~geo_df.columns.str.contains('^Unnamed')]

# Ensure that 'longitude' and 'latitude' columns are of numeric type
geo_df['longitude'] = pd.to_numeric(geo_df['longitude'], errors='coerce')
geo_df['latitude'] = pd.to_numeric(geo_df['latitude'], errors='coerce')

# Check the columns to ensure they are correctly named and of numeric type
#print("Column Names:")
#print(geo_df.columns)
#print("\nData Types:")
#print(geo_df[['longitude', 'latitude']].dtypes)
#print("\nFirst Few Rows:")
#print(geo_df[['longitude', 'latitude']].head())

# Ensure that 'longitude' and 'latitude' columns exist and are correctly named
if 'longitude' in geo_df.columns and 'latitude' in geo_df.columns:
    # Plotting using hvplot
    try:
        fig = geo_df.hvplot.points(
            'longitude', 'latitude',  geo=True, c='shape',
            color = 'red',
            #aggregator ='count',
            s='average_duration_hour',
            #width=300, height=400, subplots=True, shared_axes=False,
            hover_cols=['year', 'city', 'form'],
            groupby=['state_name'],
            # #, #'city'],
            by='form',
            widgets={'state_name': pn.widgets.RadioButtonGroup},
            muted_color = 'white',muted_alpha = 0.1,
            alpha=0.5, tiles='OSM',
            xlim=(-10,-165), ylim=(18,62), widget_location='bottom',
            #xlim=(float(cleaned_ufo_ca.longitude.min()), float(cleaned_ufo_ca.longitude.max())),
            #ylim=(float(cleaned_ufo_ca.latitude.min()), float(cleaned_ufo_ca.latitude.max()))
        )
        display(fig)  # Use display to render the plot inline in Jupyter
    except Exception as e:
        print(f"Error while plotting: {e}")
else:
    print("The columns 'longitude' and 'latitude' must be present in the DataFrame.")
